{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee850605-ad14-49cc-8a22-333a318dd05c",
   "metadata": {},
   "source": [
    "# 나이브 베이즈 알고리즘 (Naive Bayes)\n",
    "\n",
    "**나이브 베이즈(Naive Bayes)**는 확률 이론과 베이즈 정리를 기반으로 한 **지도 학습(Supervised Learning)** 알고리즘입니다. 주로 **분류(Classification)** 문제에 사용되며, 제한적인 상황에서 **회귀(Regression)** 문제에도 활용될 수 있습니다.\n",
    "\n",
    "---\n",
    "\n",
    "## 나이브 베이즈의 특징\n",
    "1. **베이즈 정리(Bayes Theorem) 기반**:\n",
    "   - 베이즈 정리를 활용하여 데이터의 클래스 조건부 확률을 계산합니다.\n",
    "   - 베이즈 정리:\n",
    "     \\[\n",
    "     P(C|X) = \\frac{P(X|C) \\cdot P(C)}{P(X)}\n",
    "     \\]\n",
    "     - \\(P(C|X)\\): 주어진 데이터 \\(X\\)에 대한 클래스 \\(C\\)의 조건부 확률.\n",
    "     - \\(P(X|C)\\): 클래스 \\(C\\)에 대한 데이터 \\(X\\)의 조건부 확률.\n",
    "     - \\(P(C)\\): 클래스 \\(C\\)의 사전 확률(Prior Probability).\n",
    "     - \\(P(X)\\): 데이터 \\(X\\)의 사전 확률.\n",
    "\n",
    "2. **나이브 가정**:\n",
    "   - 모든 특징(feature)이 서로 독립적이라고 가정합니다.\n",
    "   - 실제로 독립성이 완벽하지 않더라도 성능이 우수한 경우가 많습니다.\n",
    "\n",
    "3. **빠르고 효율적**:\n",
    "   - 계산량이 적으며, 대규모 데이터셋에도 적합합니다.\n",
    "\n",
    "---\n",
    "\n",
    "## 나이브 베이즈의 종류\n",
    "1. **가우시안 나이브 베이즈 (Gaussian Naive Bayes)**:\n",
    "   - 특징이 연속적인 값을 가지며, 가우시안(정규) 분포를 따르는 경우에 사용.\n",
    "\n",
    "2. **멀티노미얼 나이브 베이즈 (Multinomial Naive Bayes)**:\n",
    "   - 특징이 이산적 값(예: 단어 빈도)인 경우에 적합.\n",
    "\n",
    "3. **베르누이 나이브 베이즈 (Bernoulli Naive Bayes)**:\n",
    "   - 특징이 이진 값(0과 1)인 경우에 적합.\n",
    "\n",
    "---\n",
    "\n",
    "## 나이브 베이즈의 장단점\n",
    "### 장점\n",
    "1. **속도**:\n",
    "   - 간단한 구조로 인해 매우 빠르게 동작.\n",
    "2. **대규모 데이터 적합**:\n",
    "   - 학습 및 예측이 효율적이며, 대규모 데이터에도 성능이 우수.\n",
    "3. **다양한 데이터 유형 지원**:\n",
    "   - 연속형 데이터, 이산형 데이터 모두 처리 가능.\n",
    "\n",
    "### 단점\n",
    "1. **독립 가정의 한계**:\n",
    "   - 특징 간 상관관계가 강할 경우 성능이 저하될 수 있음.\n",
    "2. **정확도**:\n",
    "   - 복잡한 데이터셋에서는 다른 알고리즘에 비해 성능이 떨어질 수 있음.\n",
    "\n",
    "---\n",
    "\n",
    "## 나이브 베이즈의 활용 사례\n",
    "1. **이메일 스팸 필터링**:\n",
    "   - 베르누이 나이브 베이즈를 사용하여 스팸 여부를 판별.\n",
    "2. **문서 분류**:\n",
    "   - 멀티노미얼 나이브 베이즈를 활용해 텍스트 분류(예: 뉴스 기사 카테고리).\n",
    "3. **질병 진단**:\n",
    "   - 가우시안 나이브 베이즈로 환자의 증상 데이터를 바탕으로 질병 예측.\n",
    "4. **추천 시스템**:\n",
    "   - 사용자 행동 데이터를 분석하여 맞춤형 추천 제공.\n",
    "\n",
    "---\n",
    "\n",
    "## 나이브 베이즈의 회귀 적용\n",
    "나이브 베이즈는 기본적으로 **분류 알고리즘**으로 설계되었지만, 확장 방식을 통해 **회귀 문제**에도 사용할 수 있습니다. 회귀 문제에서는 Gaussian Naive Bayes를 활용하여 연속형 데이터를 처리할 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cdba905-5f7a-451d-bd17-0255b1c26f84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032915b4-3cef-4c23-88c2-89de69cb0eb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "be0d5d87-2f64-4c3d-872e-d8ac28624534",
   "metadata": {},
   "source": [
    "## 1. Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cabf87d0-6ce9-4c22-a84a-16717ebf7cb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.00\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        10\n",
      "  versicolor       1.00      1.00      1.00         9\n",
      "   virginica       1.00      1.00      1.00        11\n",
      "\n",
      "    accuracy                           1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load dataset\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# Split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Naive Bayes classifier\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = gnb.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.2f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=iris.target_names))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123a0235-a609-4bdd-92ba-46568a47bbfa",
   "metadata": {},
   "source": [
    "## 2. Regression (Gaussian Naive Bayes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93b64cd3-3dfe-4646-a032-26654b8131da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.51\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Low       0.89      0.07      0.13      1500\n",
      "      Medium       0.48      0.98      0.65      1870\n",
      "        High       0.80      0.25      0.38       758\n",
      "\n",
      "    accuracy                           0.51      4128\n",
      "   macro avg       0.72      0.43      0.39      4128\n",
      "weighted avg       0.69      0.51      0.41      4128\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import numpy as np\n",
    "\n",
    "# Load dataset\n",
    "housing = fetch_california_housing()\n",
    "X, y = housing.data, housing.target\n",
    "\n",
    "# Convert continuous labels to categorical (e.g., low, medium, high)\n",
    "y_binned = np.digitize(y, bins=[1.5, 3.0])  # Bins: [0-1.5: Low, 1.5-3.0: Medium, >3.0: High]\n",
    "\n",
    "# Split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_binned, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Gaussian Naive Bayes\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = gnb.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.2f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=[\"Low\", \"Medium\", \"High\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2446af-654a-448d-b738-436bb37e1433",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
